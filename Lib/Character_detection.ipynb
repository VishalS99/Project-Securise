{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Character detection.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "W_BIBs356mqD"
      },
      "source": [
        "import cv2\n",
        "import os\n",
        "import numpy\n",
        "from PIL import Image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BsAjLqVQ-Fij"
      },
      "source": [
        "label_list = ['0','1','2','3','4','5','6','7','8','9', 'A','B','C','D','E','F','G','H', 'I','J','K','L','M','N','O','P','Q','R','S','T','U','V','W','X','Y','Z','a','b','c','d','e','f','g','h','i','j','k','l','m','n','o','p','q','r','s','t','u','v','w','x','y','z',]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0RBSPT4t85Ne"
      },
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from torchvision import datasets\n",
        "from torchvision import transforms\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision.io import read_image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cKUhm8e2_HsP"
      },
      "source": [
        "transform = transforms.Compose(\n",
        "    [\n",
        "    #  transforms.ToPILImage(),\n",
        "    #  transforms.Grayscale(num_output_channels=1),\n",
        "    #  transforms.Resize((28,28)),\n",
        "     transforms.ToTensor(),\n",
        "    #  transforms.Normalize((0.5), (0.5)),\n",
        "     ]\n",
        ")\n",
        "\n",
        "def load_dataset_t():\n",
        "  data_path = './Hnd/'\n",
        "  # train_dataset = datasets.ImageFolder(\n",
        "  #     root=data_path,\n",
        "  #     transform=transform\n",
        "  # )\n",
        "  train_dataset = datasets.EMNIST(root=  \"./data\",split=\"byclass\", train = True, download = False, transform = transform)\n",
        "  train_loader = torch.utils.data.DataLoader(\n",
        "      train_dataset,\n",
        "      batch_size=128,\n",
        "      num_workers=2,\n",
        "      shuffle=True\n",
        "  )\n",
        "  return train_loader\n",
        "\n",
        "def load_dataset_ts():\n",
        "  data_path = './Hnd/'\n",
        "  # train_dataset = datasets.ImageFolder(\n",
        "  #     root=data_path,\n",
        "  #     transform=transform\n",
        "  # )\n",
        "  test_dataset = datasets.EMNIST(root=  \"./data\",split=\"byclass\", train = False, download = False, transform = transform)\n",
        "  test_loader = torch.utils.data.DataLoader(\n",
        "      test_dataset,\n",
        "      batch_size=64,\n",
        "      num_workers=2,\n",
        "      shuffle=True\n",
        "  )\n",
        "  return test_loader"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ECdbe6DZHhNe",
        "outputId": "76c8725f-4cbd-4b33-fa0a-e98333f047e6"
      },
      "source": [
        "# load_dataset()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "siYSbY7DHyxE"
      },
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dataiter = iter(load_dataset_t())\n",
        "images, labels = dataiter.next()\n",
        "\n",
        "# print(images.shape)\n",
        "# print(labels.shape)\n",
        "\n",
        "# plt.imshow(images[0].numpy().squeeze(), cmap='gray_r');\n",
        "figure = plt.figure()\n",
        "num_of_images = 60\n",
        "for index in range(1, num_of_images + 1):\n",
        "    plt.subplot(6, 10, index)\n",
        "    plt.axis('off')\n",
        "    plt.imshow(images[index].numpy().squeeze(), cmap='gray_r')\n",
        "    # print(labels[index])\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "DNFZU906H7cj",
        "outputId": "c3c55d6d-9443-4d50-8ae4-d9ba00758934"
      },
      "source": [
        "device"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch.nn.functional as F\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gyUtTcI8I5MR"
      },
      "source": [
        "# defining the model architecture\n",
        "class Net(torch.nn.Module):   \n",
        "  def __init__(self):\n",
        "      super(Net, self).__init__()\n",
        "\n",
        "      self.cnn_layers = torch.nn.Sequential(\n",
        "          # Defining a 2D convolution layer\n",
        "          torch.nn.Conv2d(1, 4, kernel_size=3, stride=1, padding=1),\n",
        "          torch.nn.BatchNorm2d(4),\n",
        "          torch.nn.ReLU(inplace=True),\n",
        "          torch.nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "          # Defining another 2D convolution layer\n",
        "          torch.nn.Conv2d(4, 4, kernel_size=3, stride=1, padding=1),\n",
        "          torch.nn.BatchNorm2d(4),\n",
        "          torch.nn.ReLU(inplace=True),\n",
        "          torch.nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "      )\n",
        "\n",
        "      self.linear_layers = torch.nn.Sequential(\n",
        "          torch.nn.Linear(4 * 7 * 7, 62)\n",
        "      )\n",
        "\n",
        "  # Defining the forward pass    \n",
        "  def forward(self, x):\n",
        "      x = self.cnn_layers(x)\n",
        "      x = x.view(x.size(0), -1)\n",
        "      # print(x.size)\n",
        "      x = self.linear_layers(x)\n",
        "      return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tQp-zWymQoeH"
      },
      "source": [
        "model = Net()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.05,\n",
        "                      momentum=0.5)\n",
        "cc = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "model.cuda()\n",
        "cc = cc.cuda()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GSbGpaqQSW_O",
        "outputId": "9c87be54-c527-4e6c-cc59-87928be57014"
      },
      "source": [
        "model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-HXyy-n3SdM3"
      },
      "source": [
        "for i in range(30):\n",
        "    running_loss = 0\n",
        "    for batch_idx, (images, labels) in enumerate(load_dataset_t()):\n",
        "        if torch.cuda.is_available():\n",
        "          images = images.cuda()\n",
        "          labels = labels.cuda()\n",
        "\n",
        "        # Training pass\n",
        "        optimizer.zero_grad()\n",
        "        output = model(images)\n",
        "        loss = cc(output, labels)\n",
        "        \n",
        "        #This is where the model learns by backpropagating\n",
        "        loss.backward()\n",
        "        \n",
        "        #And optimizes its weights here\n",
        "        optimizer.step()\n",
        "        \n",
        "        running_loss += loss.item()\n",
        "    else:\n",
        "        print(\"Epoch {} - Training loss: {}\".format(i+1, running_loss/len(load_dataset_t())))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "odSpeo2ivPZo"
      },
      "source": [
        "torch.save(model, './model_character_detect.pt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "mm = torch.load('./model_character_detect.pt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "tags": []
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the network on the 10000 test images: 82 %\n"
          ]
        }
      ],
      "source": [
        "total = 0\n",
        "mm.eval()\n",
        "correct = 0\n",
        "with torch.no_grad():\n",
        "    for batch_idx, (images, labels) in enumerate(load_dataset_ts()):\n",
        "        if torch.cuda.is_available():\n",
        "          images = images.cuda()\n",
        "          labels = labels.cuda()\n",
        "        outputs = mm(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "    print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
        "        100 * correct / total))"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 82
        },
        "id": "j4qx0pNe0hl6",
        "outputId": "1bae8e06-c8cc-4b69-e284-974622c580f6"
      },
      "source": [
        "image = Image.open(\"../Images/segmentation2/image_2_ROI_1.png\")\r\n",
        "image\r\n"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<PIL.PngImagePlugin.PngImageFile image mode=L size=225x325 at 0x7FBD0C7FB9D0>"
            ],
            "image/png": "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\n"
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [],
      "source": [
        "transform = transforms.Compose(\n",
        "    [\n",
        "    #  transforms.ToPILImage(),\n",
        "     transforms.Grayscale(num_output_channels=1),\n",
        "     transforms.Resize((28,28)),\n",
        "     transforms.ToTensor(),\n",
        "    #  transforms.Normalize((0.5), (0.5)),\n",
        "     ]\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I8gapoSS2piM"
      },
      "source": [
        "image = transform(image)\r\n",
        "image = image.cuda()"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CbxWzrqH2rBV",
        "outputId": "1c24c412-d1d9-4281-a836-ef25d69ecf5f"
      },
      "source": [
        "mm\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ycH8UxyY32ZV"
      },
      "source": [
        "# image = image.cuda()\r\n",
        "lp = mm(image[None, ...])"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KVdxNKOpAmn2"
      },
      "source": [
        "ps = torch.exp(lp)\r\n",
        "probab = list(ps.cpu()[0])\r\n",
        "pred_label = probab.index(max(probab))"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zxoQM9odAuX7",
        "outputId": "6278cc0d-cf16-4308-ff09-acc36e3304ae"
      },
      "source": [
        "lp"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[  9.7822,  -9.2660,   1.0041,   1.2574, -21.2339,   7.8191,  -0.9486,\n",
              "          -7.9979,  10.4634,   4.2336,   3.9629,  15.7870,   3.9940,  20.1944,\n",
              "           4.2583,  -0.2584,   9.0266, -22.9915,  10.7060,  12.0631,  -7.8693,\n",
              "          -7.6812,  -7.0087,  -1.4249,  12.9591,   0.8182,  12.7905,  12.0966,\n",
              "           3.2855,   0.1476,  -2.2615,  -8.1726,  -0.6786,  -6.0806,  -7.1914,\n",
              "           7.6328,  10.1098,  -3.2158,  -2.4524,  -4.4376,   3.5000,  -2.5345,\n",
              "          11.0136,  -9.6387,  -5.5496,  -3.6103,  -7.7525,  -3.5272,  -5.7489,\n",
              "          -1.1082,   7.4813,   1.3978,   9.5256,  -5.7517,   1.1410, -12.7823,\n",
              "          -7.5822,  -8.7728,  -2.8349,  -7.7433,  -9.6235,   1.7765]],\n",
              "       device='cuda:0', grad_fn=<AddmmBackward>)"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RXMWE8WQAyMS",
        "outputId": "7629fe6a-e7a0-4e0a-82a9-2e30e6a220a8"
      },
      "source": [
        "max(probab)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(1.6476e+29, grad_fn=<UnbindBackward>)"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "S3lz0SDFAw4F",
        "outputId": "7319098e-6d80-45bb-d17c-e3fd01c41d4e"
      },
      "source": [
        "label_list[pred_label]"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'D'"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    }
  ]
}